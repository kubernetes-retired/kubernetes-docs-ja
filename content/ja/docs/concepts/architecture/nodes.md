---
title: ノード
content_template: templates/concept
weight: 10
---

{{% capture overview %}}

`node` （ノード）とは、 Kubernetes における作業マシン（worker machine）であり、以前は `minion` （ミニオン）として知られていました。
ノードは仮想マシンまたは物理マシンであり、クラスタに依存します。
各ノードでサービスに欠かせないのが [ポッド](/jp/docs/concepts/workloads/pods/pod/) の実行と、ポッドがマスタ・コンポーネント（構成要素）によって管理されることです。
ノード上のサービスとして含まれるのは Docker 、kubectl 、kube-proxy です。
アーキテクチャ設計ドキュメントの [Kubernetes Node](https://git.k8s.io/community/contributors/design-proposals/architecture/architecture.md#the-kubernetes-node) セクションに詳細があります。


{{% /capture %}}

{{< toc >}}

{{% capture body %}}

## ノード状態（status）{#node-status}

ノードの状態には以下の情報を含みます:

* [アドレス](#addresses)
* [状況](#condition)
* [キャパシティ](#capacity)
* [情報](#info)

以下の各セクションで詳細を説明します。

### アドレス {#addresses}

各フィールドの使い方は、クラウド事業者やベアメタル設定情報に依存して変わります。

* ホスト名（HostName）：ノードのカーネルが報告するホスト名（hostname）です。kubelet の `--hostname-override` パラメータいよって上書きできます。
* 外部 IP（ExternalIP）：ノードの典型的な IP アドレスであり、外部に径路付けが可能（ルーティング可能／routable）です（クラスタの外からも利用できます）。
* 内部 IP（InternalIP）：ノードの典型的な IP アドレスであり、クラスタ内でのみ径路付けが可能（ルーティング可能）です。

### 状況（Condition） {#condition}

`conditions` （状況）フィールドは、全ての `Running`（実行中）ノードのステータス（状態）を説明します。

| ノード状況 | 説明 |
|----------------|-------------|
| `OutOfDisk`    | `True` の場合、新しいポッドをノードに追加するための十分な空きスペースが無い状態。そうでなければ `False` |
| `Ready`        | `True` の場合は、ノードが正常（healthy）かつポッドの受け入れ準備が整っている状態。 `False` はノードが正常ではなく、ポッドを受け入れられない状態。 `Unknows` （不明）はノード・コントローラがノードからの応答が直近の `node-monitor-grace-period` （ノード監視猶予間隔）(デフォルトは 40 秒) 以内に無かった状態。 |
| `MemoryPressure`    | `True`の場合、ノード・メモリ上に圧力（プレッシャー）が存在する。つまり、ノードのメモリが少ない。そうでなければ `False` |
| `PIDPressure`    | `True` の場合、プロセス上に圧力（プレッシャー）が存在する。つまり、ノード上に多くのプロセスが存在している。そうでなければ `False` |
| `DiskPressure`    | `True` の場合、ディスク容量上にプレッシャーが存在する。つまり、ディスク空き容量（キャパシティ）が少ない。そうでなければ `False` |
| `NetworkUnavailable`    | `True` の場合、ノードのネットワークが適切に設定されていない。そうでなければ `False` |
| `ConfigOK`    | `True`の場合、kubeletは適切に設定されている。そうでなければ `False` |

ノード設定は JSON オブジェクトとして表示されます。
たとえば、以下は正常な（healthy）ノードの応答です。

```json
"conditions": [
  {
    "type": "Ready",
    "status": "True"
  }
]
```

待機状態が "Unknown"（不明）もしくは "False" が `pod-eviction-timeout` （ポッド退避タイムアウト）よりも長くなれば、引数（argument）が [kube-controller-manager](/jp/docs/admin/kube-controller-manager/) に渡され、ノード・コントローラによって、ノード上にあるポッド全ての削除がスケジュールされます。
デフォルトの退避タイムアウト期間は **５分間** です。
場合によっては、ノードとの疎通がとれなくなり、apiserver は対象ノード上の kubelet とが通信できなくなります。
apiserver との通信が再確立できないようであれば、 kubelet と通信できないポッドの削除を検討します。
そうこうしているうちに、隔たれたノード上で実行しているポッドの削除がスケジュールされてしまいます。

Kubernetes 1.5 未満のバージョンでは、apiserver から到達しないポッドに対して、ノード・コントローラは [強制削除（force delete）](/jp/docs/concepts/workloads/pods/pod/#force-deletion-of-pods) を行います。
しかしながら、1.5 および以降のバージョンでは、ノード・コントローラは確認のない強制削除は行わず、クラスタ上での実行が止まっているものとします。
これにより、到達できないノード上で実行している可能性のあるポッドは、「Terminating」（終了中）もしくは「Unknown」（不明）状態として表示されます。
念のため、Kubernetes は基盤を支えるインフラ上にあるノードが、クラスタから永久に切り離されたとは想定しません。
クラスタの管理者が、ノード・オブジェクトを手動で削除する必要があります。
Kubernetes からノード・オブジェクトを削除すると、そこで動いている全てのポッド・オブジェクトも apiserver によって削除されます。これは、名前による制限を解かれるからです。

バージョン 1.8 では状況を表す [taint（テイント）](/jp/docs/concepts/configuration/taint-and-toleration/)  を自動的に作成するアルファ機能が導入されました。
この挙動を有効にすると、API サーバ、コントローラ、マネージャ、スケジューラに対して、追加機能ゲート・フラグ `--feature-gates=...,TaintNodesByCondition=true` を渡します。
もしも `TaintNodesByCondition` が有効であれば、スケジューラはノードの状況考慮を無視します。
つまり、そのかわりにノードのテイントとポッドの耐性が得られます。

これでユーザは古いスケジューリング方式か、新しいより柔軟なスケジューリング方式かを選択できるようになりました。
ポッドは古いモデルで言うところのスケジュールに対する耐性を持ちません。
しかし、ポッドの耐性とはノードでテイント（故障）が起こったとしても、別のノードでスケジュールされうるからです。

状況が発見されてテイントが作成されるまでは、常に１秒以下のわずかな遅延が起こるためご注意ください。
これにより、この機能を有効化すると作成されるポッドの数がわずかに増える可能性があります。
これはスケジュールに成功しても、kubelet によって拒否（rejected）されたものがあるからです。

### キャパシティ（Capacity） {#capacity}

ノード上で利用可能なリソースを示します。
たとえば、CPU、メモリ、ノード上にスケジュールできるポッドの最大数です。


### 情報 {#info}

ノードに関する一般的な情報を表示します。
たとえば、カーネルのバージョン、Kubernetes バージョン（kubelet および kube-proxy バージョン）、Docker バージョン（もし使っていれば）、OS 名などです。
情報は kubelet によってノードから集められます。

## 管理 {#management}

[ポッド](/jp/docs/concepts/workloads/pods/pod/) や [サービス](/jp/docs/concepts/services-networking/service/) とは異なり、ノードは本質的に Kubernetes によって作成されるものではありません。
つまり、ノードとは Google Compute Engine のようなクラウド事業者によって外部で作成されるか、既存の物理または仮想マシンのプール上にあります。
これが意味するのは、Kubernetes でノードを作成する時に、実際に作成するオブジェクトとはノードに相当する（意味を持つ）ものです。
作成後、Kubernetes はノードが有効かどうかの確認をします。
たとえば、以下の内容のノードを作成しようとします：

```json
{
  "kind": "Node",
  "apiVersion": "v1",
  "metadata": {
    "name": "10.240.79.157",
    "labels": {
      "name": "my-first-k8s-node"
    }
  }
}
```

Kubernetes はノード・オブジェクトを内部に（表面上は）作成します。
そして、ノードが有効かどうかを、`metadata.name` フィールドをベースとした正常性チェック（health check）で行います（ `metadata.name` で名前解決できると想定します）。
ノードが有効であれば、たとえば、全ての必要なサービスが実行中であれば、ポッドを実行する資格があります。
もしも有効でなければ、有効になるまでは、あらゆるクラスタ活動が無視されます。
クライアントによってノード削除を明示しない限り、Kubernetes は無効なノードのオブジェクトを維持しますのでご注意ください。
また、有効になったとしてもチェックは継続します。

現時点では３つの構成要素（コンポーネント）が Kubernetes ノード・インターフェースと通信します。ノード・コントローラ、kubelet、kubectl です。

### ノード・コントローラ（Node Controller）{#node-controller}

ノード・コントローラは Kubernetes の主要な構成要素（コンポーネント）であり、ノードの様々な面を管理します。

ノード・コントローラはノードの寿命（life）において複数の役割を持ちます。
はじめに割り当てられるのは、ノードが登録された時、ノードに対する CIDR ブロックです（CIDR 割り当てが有効な場合）。

２つめは、ノード・コントローラが内部に維持するノード一覧を、クラウド・プロバイダで利用可能なマシン一覧に更新することです。
クラウド環境で実行すると、ノードが障害（unhealthy）でなければ、ノード・コントローラはクラウド・プロバイダに対して、ノードが利用可能な VM があるかどうかを訊ねます。
もしそうでなければ、ノード・コントローラはノード一覧から、この対象となるノードを削除します。

３つめは、ノード正常性の監視です。
ノード・コントローラはノードに到達不能になり（例：何らかの理由によってハードビードを受信してノード・コントローラ停止、あるいは、ノードの停止が始まったことにより）、 NodeStatus（ノード状態）が ConditionUnknown （状況不明）であれば、  NodeReady（ノード待機）状態に更新する責任を持ちます。
また、その後もノードに到達不能の状態が継続する場合は、（丁寧な停止を使い）ノード上の全てのポッドを退避します（デフォルトのタイムアウトは ConditionUnknown の報告後 40 秒で、5分経過するとポッドの退避を開始）。
ノード・コントローラは  `--node-monitor-period` 秒ごとに状態を確認します。

Kubernetes 1.4 では、私たちはノード・コントローラのロジックを更新し、多くのノードがあるときもマスタに到達できない問題がおこらず、上手に扱えるようにしました（例：マスタにネットワーク上の問題がある場合）。
1.4 からは、ポッドの退避を決めるにあたり、ノード・コントローラがクラスタ内の全てのノード状態を観察します。

ほとんどの場合、ノード・コントローラは1秒あたりの退避レートを `--node-eviction-rate` で指定しています（デフォルトは 0.1）。
つまり、１ノードあたり 10 秒を越えて、ポッドを退避しません。

ノード退避の挙動が変わるのは、ノードが稼働している availability ゾーンが異常（unhealthy）になった時です。
ノード・コントローラはゾーン内の何パーセントのノードが同時に異常（NodeReady 状態が ConditionUnknown もしくは ConditionFalse）になっているかどうかを調べます。
もし、異常ノードがごく少量のノードで、`--unhealthy-zone-threshold` (デフォルト 0.55)  以下であれば、退避レートを減少します。たとえば、クラスタが小さければ（例：`--large-cluster-size-threshold` で指定した値よりもノードが等しいか少なくなるように。デフォルトは 50 ） 退避は停止します。
そうでなければ、退避レートは１秒ごとに `--secondary-node-eviction-rate` ずつ（デフォルトは 0.01）減少します。
これらの方針（ポリシー）をアベイラビリティ・ゾーンごとに実装されているのは、１つのアベイラビリティ・ゾーンが他と通信中にもかかわらずマスタから切り離されてしまう可能性があるためです。
もしクラスタがクラウド事業者にある複数のアベイラビリティ・ゾーンを横断しないのであれば、アベイラビリティ・ゾーン（クラスタ全体）は１つしかないことになります。

アベイラビリティ・ゾーンを横断してノードが拡散する主な理由は、あるノード全体で障害が発生（ダウン）した時、正常なゾーンにワークロードが移行するためです。
そのため、ゾーン内の全てのノードが異常（unhealthy）になれば、通常はレート（比率）が `--node-eviction-rate` を越えると、ノード・コントローラは退避します。
このような場合、ノード・コントローラはマスタとの疎通に何らかの問題が発生したと見なし、どこかとの接続性が回復するまで、全ての退避は停止したままにします。

Kubernetes 1.6 以降、NodeController もポッドの退避に責任を持つようになりました。
ポッドがテイントに対する耐性（tolerate）がなければ、 `NoExecute` （実行でいない）テイントを持つノード上で実行しているポッドを NodeController が退避します。
なお、これはアルファ機能のため、デフォルトでは無効化されています。
NodeController が責任を持つのは、ノードに到達できない場合や準備ができていないなどノードの問題に対して、適切にテイントを追加することです。

バージョン 1.8 からは、ノード・コントローラはノード状態を表すテイントの作成に責任を持つことになりました。
これはバージョン 1.8 のアルファ機能です。

### ノードの自己登録 {#self-registration-of-nodes}

kubelet のフラグ `--register-node` が true であれば（デフォルトです）、kubelet は自分自身を API サーバへの登録を試みます。
これが望ましい形態（パターン）であり、多くのディストリビューションで使われています。

自分で登録する（self-registration）には、以下のオプションで kubelet を起動します。

  - `--kubeconfig` - apiserver に自分自身を登録するために使う信用証明（credential）のパス。
  - `--cloud-provider` - クラウド事業者と通信するために使う、自分自身に関するメタデータ。
  - `--register-node` - API サーバの自動的に登録。
  - `--register-with-taints` - ノードを指定したテイント（taint）の一覧に基づき登録（カンマ区切りの `<キー>=<値>:<効果>`）。もし `register-node` が false であれば何も行いません。
  - `--node-ip` - ノードの IP アドレス。
  - `--node-labels` - クラスタにノードを登録するときのラベルを追加。
  - `--node-status-update-frequency` - kubelet がノードのステータスを master に何回ポストするかを指定

現在の所、どのようなノード・リソースに対しても kubelet は作成・変更する権限を持っています。
しかし、現実的に破作成・変更は自分自身に留めます（将来的には、kubelet は自分自身のノード・リソースのみ変更できるようにするのを計画しています）。

#### 手動のノード管理 {#manual-node-administration}

クラスタの管理者はノード・オブジェクトの作成と変更を行えます。

管理者がノード・オブジェクトを手動で作りたい場合は、kubelet にフラグ `--register-node=false`  を指定します。

管理者はノード・リソースの変更が可能です（ `--register-node` の設定を無視します）。

ノード上のラベルは、ポッド上のノード・セレクタとスケジューリング管理を連結（結び付ける）ために使います。
たとえば、適切なノードのサブセット上でのみ実行するポッドを制限する場合です。

スケジュール不可能（unschedulable）とマーク（印付け）されたノードには、新しいポッドがスケジュールされるのを阻止します。
ですが、これはノードが対象であり、ノード上にある既存のポッドに対しては何ら影響はありません。
これはノードの再起動など、事前の準備段階に使うのが便利です。
たとえば、ノードをスケジュール不可能と印を付けるには、次のコマンドを実行します。

```shell
kubectl cordon $NODENAME
```

DaemonSet コントローラが Kubernetes スケジューラをバイパスして作成されたポッドは、ノードのスケジュール不可能な属性を一切考慮しません。
これは、デーモンが対象マシン上に存在していると仮定しているためで、たとえ再起動の準備のためにアプリケーションのドレイン（排出）を行っているとしてもです。

### ノードの収容能力（キャパシティ） {#node-capacity}

ノードの許容能力（CPU 数、メモリ容量）とはノード・オブジェクトの一部です。
通常、ノード・オブジェクトの作成時、ノードは自分自身を登録し、自身の許容能力（キャパシティ）を報告します。
もしも [ノードの手動管理](#manual-node-administration) を考えている場合は、ノードの追加時にノード許容容量を設定する必要があります。

Kubernetes スケジューラは、ノード上の全てのポッドに対して十分なリソースがあるのを確保します。
スケジューラはノード上にあるコンテナの要求を合計し、ノードの許容容量（キャパシティ）を越えないようにチェックします。
これには kubelet によって作成された全てのコンテナを含みます。
しかし、Docker が直接開始したコンテナや、コンテナ内に入っていないプロセスは含みません。

ポッド以外のプロセスに対しても、明示的にリソースを予約したい場合は、 代替ポッド（placeholder pod）を作成できます。 
以下のテンプレートをお使いください。


```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-reserver
spec:
  containers:
  - name: sleep-forever
    image: k8s.gcr.io/pause:0.8.0
    resources:
      requests:
        cpu: 100m
        memory: 100Mi
```

予約したいリソース量の `cpu` と `memory` を設定します。
マニフェスト・ディレクトリ内（ kubelet の `--config=DIR` フラグ）にこのファイルを置きます。
この作業を、リソースを予約したい各 kubelet 上で行います。

## API オブジェクト {#api-object}

ノードは Kubernetes REST API の中でトップ・レベルのリソースです。
API オブジェクトの詳細については、 [Node API object](/jp/docs/reference/generated/kubernetes-api/{{< param "version" >}}/#node-v1-core) にあります。


{{% /capture %}}
